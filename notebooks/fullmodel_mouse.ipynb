{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from minimodel import data\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_id = 5\n",
    "\n",
    "data_path = './data'\n",
    "weight_path = './checkpoints_trained'\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw image shape:  (68000, 66, 264)\n",
      "cropped image shape:  (68000, 66, 130)\n",
      "img:  (68000, 66, 130) -2.0829253 2.1060908 float32\n"
     ]
    }
   ],
   "source": [
    "# load images\n",
    "img = data.load_images(data_path, mouse_id, file=data.img_file_name[mouse_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loading activities from ./data/FX20_nat60k_2023_09_29.npz\n"
     ]
    }
   ],
   "source": [
    "# load neurons\n",
    "fname = '%s_nat60k_%s.npz'%(data.db[mouse_id]['mname'], data.db[mouse_id]['datexp'])\n",
    "spks, istim_train, istim_test, xpos, ypos, spks_rep_all = data.load_neurons(file_path = os.path.join(data_path, fname), mouse_id = mouse_id)\n",
    "n_stim, n_neurons = spks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "splitting training and validation set...\n",
      "itrain:  (43081,)\n",
      "ival:  (4787,)\n"
     ]
    }
   ],
   "source": [
    "# split train and validation set\n",
    "itrain, ival = data.split_train_val(istim_train, train_frac=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "normalizing neural data...\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "# normalize data\n",
    "spks, spks_rep_all = data.normalize_spks(spks, spks_rep_all, itrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spks_train:  torch.Size([43081, 2746]) tensor(-1.4092e-15, device='cuda:0') tensor(48.7427, device='cuda:0')\n",
      "spks_val:  torch.Size([4787, 2746]) tensor(-6.8745e-16, device='cuda:0') tensor(44.7361, device='cuda:0')\n",
      "img_train:  torch.Size([43081, 1, 66, 130]) tensor(-2.0829, device='cuda:0') tensor(2.1061, device='cuda:0')\n",
      "img_val:  torch.Size([4787, 1, 66, 130]) tensor(-2.0829, device='cuda:0') tensor(2.1061, device='cuda:0')\n",
      "img_test:  torch.Size([500, 1, 66, 130]) tensor(-2.0829, device='cuda:0') tensor(2.1061, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "ineur = np.arange(0, n_neurons) #np.arange(0, n_neurons, 5)\n",
    "spks_train = torch.from_numpy(spks[itrain][:,ineur]).to(device)\n",
    "spks_val = torch.from_numpy(spks[ival][:,ineur]).to(device)\n",
    "\n",
    "print('spks_train: ', spks_train.shape, spks_train.min(), spks_train.max())\n",
    "print('spks_val: ', spks_val.shape, spks_val.min(), spks_val.max())\n",
    "\n",
    "img_train = torch.from_numpy(img[istim_train][itrain]).to(device).unsqueeze(1) # change :130 to 25:100 \n",
    "img_val = torch.from_numpy(img[istim_train][ival]).to(device).unsqueeze(1)\n",
    "img_test = torch.from_numpy(img[istim_test]).to(device).unsqueeze(1)\n",
    "\n",
    "print('img_train: ', img_train.shape, img_train.min(), img_train.max())\n",
    "print('img_val: ', img_val.shape, img_val.min(), img_val.max())\n",
    "print('img_test: ', img_test.shape, img_test.min(), img_test.max())\n",
    "\n",
    "input_Ly, input_Lx = img_train.shape[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core shape:  torch.Size([1, 320, 33, 65])\n",
      "input shape of readout:  (320, 33, 65)\n",
      "model name:  FX20_092923_2layer_16_320_clamp_norm_depthsep_pool_xrange_176.pt\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "from minimodel import model_builder\n",
    "nlayers = 2\n",
    "nconv1 = 16\n",
    "nconv2 = 320\n",
    "model, in_channels = model_builder.build_model(NN=len(ineur), n_layers=nlayers, n_conv=nconv1, n_conv_mid=nconv2)\n",
    "model_name = model_builder.create_model_name(data.mouse_names[mouse_id], data.exp_date[mouse_id], n_layers=nlayers, in_channels=in_channels)\n",
    "\n",
    "model_path = os.path.join(weight_path, model_name)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Learning rate = 0.001\n",
      "epoch 0, train_loss = 0.8411, val_loss = 0.8143, varexp_val = 0.0525, time 53.98s\n",
      "epoch 1, train_loss = 0.8110, val_loss = 0.8031, varexp_val = 0.0699, time 102.58s\n",
      "epoch 2, train_loss = 0.8028, val_loss = 0.7970, varexp_val = 0.0792, time 151.16s\n",
      "epoch 3, train_loss = 0.7978, val_loss = 0.7933, varexp_val = 0.0854, time 199.74s\n",
      "epoch 4, train_loss = 0.7950, val_loss = 0.7912, varexp_val = 0.0887, time 248.32s\n",
      "epoch 5, train_loss = 0.7928, val_loss = 0.7910, varexp_val = 0.0896, time 296.89s\n",
      "epoch 6, train_loss = 0.7911, val_loss = 0.7881, varexp_val = 0.0936, time 345.49s\n",
      "epoch 7, train_loss = 0.7898, val_loss = 0.7884, varexp_val = 0.0940, time 394.05s\n",
      "epoch 8, train_loss = 0.7888, val_loss = 0.7868, varexp_val = 0.0958, time 442.59s\n",
      "epoch 9, train_loss = 0.7878, val_loss = 0.7858, varexp_val = 0.0978, time 491.16s\n",
      "epoch 10, train_loss = 0.7871, val_loss = 0.7851, varexp_val = 0.0986, time 539.73s\n",
      "epoch 11, train_loss = 0.7863, val_loss = 0.7850, varexp_val = 0.0992, time 588.31s\n",
      "epoch 12, train_loss = 0.7858, val_loss = 0.7844, varexp_val = 0.0997, time 636.89s\n",
      "epoch 13, train_loss = 0.7853, val_loss = 0.7845, varexp_val = 0.1001, time 685.45s\n",
      "epoch 14, train_loss = 0.7848, val_loss = 0.7855, varexp_val = 0.0995, time 734.00s\n",
      "epoch 15, train_loss = 0.7843, val_loss = 0.7835, varexp_val = 0.1016, time 782.54s\n",
      "epoch 16, train_loss = 0.7840, val_loss = 0.7831, varexp_val = 0.1020, time 831.09s\n",
      "epoch 17, train_loss = 0.7836, val_loss = 0.7834, varexp_val = 0.1022, time 879.64s\n",
      "epoch 18, train_loss = 0.7833, val_loss = 0.7834, varexp_val = 0.1022, time 928.18s\n",
      "epoch 19, train_loss = 0.7831, val_loss = 0.7832, varexp_val = 0.1026, time 976.73s\n",
      "epoch 20, train_loss = 0.7828, val_loss = 0.7830, varexp_val = 0.1024, time 1025.30s\n",
      "epoch 21, train_loss = 0.7825, val_loss = 0.7820, varexp_val = 0.1038, time 1073.85s\n",
      "epoch 22, train_loss = 0.7824, val_loss = 0.7830, varexp_val = 0.1025, time 1122.40s\n",
      "epoch 23, train_loss = 0.7821, val_loss = 0.7823, varexp_val = 0.1035, time 1170.96s\n",
      "epoch 24, train_loss = 0.7818, val_loss = 0.7821, varexp_val = 0.1036, time 1219.51s\n",
      "epoch 25, train_loss = 0.7817, val_loss = 0.7818, varexp_val = 0.1042, time 1268.05s\n",
      "epoch 26, train_loss = 0.7815, val_loss = 0.7820, varexp_val = 0.1044, time 1316.59s\n",
      "epoch 27, train_loss = 0.7812, val_loss = 0.7818, varexp_val = 0.1045, time 1365.14s\n",
      "epoch 28, train_loss = 0.7811, val_loss = 0.7817, varexp_val = 0.1047, time 1413.68s\n",
      "epoch 29, train_loss = 0.7810, val_loss = 0.7817, varexp_val = 0.1046, time 1462.22s\n",
      "epoch 30, train_loss = 0.7810, val_loss = 0.7818, varexp_val = 0.1045, time 1510.76s\n",
      "epoch 31, train_loss = 0.7807, val_loss = 0.7813, varexp_val = 0.1053, time 1559.32s\n",
      "epoch 32, train_loss = 0.7806, val_loss = 0.7816, varexp_val = 0.1048, time 1607.86s\n",
      "epoch 33, train_loss = 0.7805, val_loss = 0.7816, varexp_val = 0.1049, time 1656.41s\n",
      "epoch 34, train_loss = 0.7803, val_loss = 0.7816, varexp_val = 0.1047, time 1704.97s\n",
      "epoch 35, train_loss = 0.7803, val_loss = 0.7813, varexp_val = 0.1054, time 1753.54s\n",
      "epoch 36, train_loss = 0.7801, val_loss = 0.7812, varexp_val = 0.1054, time 1802.10s\n",
      "epoch 37, train_loss = 0.7801, val_loss = 0.7814, varexp_val = 0.1052, time 1850.65s\n",
      "epoch 38, train_loss = 0.7800, val_loss = 0.7811, varexp_val = 0.1057, time 1899.20s\n",
      "epoch 39, train_loss = 0.7798, val_loss = 0.7812, varexp_val = 0.1057, time 1947.76s\n",
      "epoch 40, train_loss = 0.7796, val_loss = 0.7809, varexp_val = 0.1059, time 1996.30s\n",
      "epoch 41, train_loss = 0.7796, val_loss = 0.7817, varexp_val = 0.1049, time 2044.86s\n",
      "epoch 42, train_loss = 0.7795, val_loss = 0.7814, varexp_val = 0.1052, time 2093.41s\n",
      "epoch 43, train_loss = 0.7794, val_loss = 0.7816, varexp_val = 0.1054, time 2141.95s\n",
      "epoch 44, train_loss = 0.7794, val_loss = 0.7815, varexp_val = 0.1048, time 2190.51s\n",
      "epoch 45, train_loss = 0.7794, val_loss = 0.7809, varexp_val = 0.1061, time 2239.06s\n",
      "epoch 46, train_loss = 0.7792, val_loss = 0.7811, varexp_val = 0.1051, time 2287.61s\n",
      "epoch 47, train_loss = 0.7792, val_loss = 0.7817, varexp_val = 0.1048, time 2336.16s\n",
      "epoch 48, train_loss = 0.7791, val_loss = 0.7810, varexp_val = 0.1060, time 2384.70s\n",
      "epoch 49, train_loss = 0.7791, val_loss = 0.7808, varexp_val = 0.1063, time 2433.28s\n",
      "epoch 50, train_loss = 0.7790, val_loss = 0.7808, varexp_val = 0.1060, time 2482.08s\n",
      "epoch 51, train_loss = 0.7789, val_loss = 0.7810, varexp_val = 0.1060, time 2530.78s\n",
      "epoch 52, train_loss = 0.7789, val_loss = 0.7803, varexp_val = 0.1070, time 2579.44s\n",
      "epoch 53, train_loss = 0.7789, val_loss = 0.7807, varexp_val = 0.1063, time 2627.98s\n",
      "epoch 54, train_loss = 0.7788, val_loss = 0.7809, varexp_val = 0.1060, time 2676.52s\n",
      "epoch 55, train_loss = 0.7787, val_loss = 0.7805, varexp_val = 0.1068, time 2725.06s\n",
      "epoch 56, train_loss = 0.7786, val_loss = 0.7808, varexp_val = 0.1062, time 2773.64s\n",
      "epoch 57, train_loss = 0.7787, val_loss = 0.7812, varexp_val = 0.1055, time 2822.33s\n",
      "Early stopping at epoch 57 due to no improvement in validation varexp.\n",
      "Learning rate = 0.0003333333333333333\n",
      "epoch 0, train_loss = 0.7757, val_loss = 0.7786, varexp_val = 0.1099, time 48.70s\n",
      "epoch 1, train_loss = 0.7751, val_loss = 0.7787, varexp_val = 0.1099, time 97.24s\n",
      "epoch 2, train_loss = 0.7749, val_loss = 0.7785, varexp_val = 0.1099, time 145.80s\n",
      "epoch 3, train_loss = 0.7748, val_loss = 0.7786, varexp_val = 0.1103, time 194.36s\n",
      "epoch 4, train_loss = 0.7748, val_loss = 0.7786, varexp_val = 0.1099, time 242.92s\n",
      "epoch 5, train_loss = 0.7747, val_loss = 0.7789, varexp_val = 0.1096, time 291.48s\n",
      "epoch 6, train_loss = 0.7747, val_loss = 0.7788, varexp_val = 0.1095, time 340.04s\n",
      "epoch 7, train_loss = 0.7746, val_loss = 0.7788, varexp_val = 0.1099, time 388.60s\n",
      "epoch 8, train_loss = 0.7747, val_loss = 0.7789, varexp_val = 0.1090, time 437.14s\n",
      "Early stopping at epoch 8 due to no improvement in validation varexp.\n",
      "Learning rate = 0.00011111111111111112\n",
      "epoch 0, train_loss = 0.7735, val_loss = 0.7778, varexp_val = 0.1112, time 48.56s\n",
      "epoch 1, train_loss = 0.7732, val_loss = 0.7780, varexp_val = 0.1110, time 97.11s\n",
      "epoch 2, train_loss = 0.7731, val_loss = 0.7779, varexp_val = 0.1111, time 145.66s\n",
      "epoch 3, train_loss = 0.7731, val_loss = 0.7779, varexp_val = 0.1115, time 194.22s\n",
      "epoch 4, train_loss = 0.7730, val_loss = 0.7780, varexp_val = 0.1111, time 242.77s\n",
      "epoch 5, train_loss = 0.7730, val_loss = 0.7780, varexp_val = 0.1110, time 291.32s\n",
      "epoch 6, train_loss = 0.7729, val_loss = 0.7781, varexp_val = 0.1107, time 339.87s\n",
      "epoch 7, train_loss = 0.7729, val_loss = 0.7779, varexp_val = 0.1113, time 388.43s\n",
      "epoch 8, train_loss = 0.7729, val_loss = 0.7779, varexp_val = 0.1107, time 436.98s\n",
      "Early stopping at epoch 8 due to no improvement in validation varexp.\n",
      "Learning rate = 3.7037037037037037e-05\n",
      "epoch 0, train_loss = 0.7725, val_loss = 0.7777, varexp_val = 0.1114, time 48.56s\n",
      "Early stopping at epoch 0 due to no improvement in validation varexp.\n",
      "saved model ./checkpoints_trained/FX20_092923_2layer_16_320_clamp_norm_depthsep_pool_xrange_176.pt\n",
      "loaded model ./checkpoints_trained/FX20_092923_2layer_16_320_clamp_norm_depthsep_pool_xrange_176.pt\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "from minimodel import model_trainer\n",
    "print(device)\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    best_state_dict = model_trainer.train(model, spks_train, spks_val, img_train, img_val, device=device)\n",
    "    torch.save(best_state_dict, model_path)\n",
    "    print('saved model', model_path)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "print('loaded model', model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_pred:  (500, 2746) 0.001676619 9.360834\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "test_pred = model_trainer.test_epoch(model, img_test)\n",
    "print('test_pred: ', test_pred.shape, test_pred.min(), test_pred.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering neurons with FEV > 0.15\n",
      "valid neurons: 1239 / 2746\n",
      "FEVE (test): 0.7180569171905518\n"
     ]
    }
   ],
   "source": [
    "from minimodel import metrics\n",
    "test_fev, test_feve = metrics.feve(spks_rep_all, test_pred)\n",
    "\n",
    "threshold = 0.15\n",
    "print(f'filtering neurons with FEV > {threshold}')\n",
    "valid_idxes = np.where(test_fev > threshold)[0]\n",
    "print(f'valid neurons: {len(valid_idxes)} / {len(test_fev)}')\n",
    "print(f'FEVE (test): {np.mean(test_feve[test_fev > threshold])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minimodel-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
