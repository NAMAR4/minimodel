{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from minimodel import data\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_id = 5\n",
    "\n",
    "data_path = './data'\n",
    "weight_path = './checkpoints'\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw image shape:  (68000, 66, 264)\n",
      "cropped image shape:  (68000, 66, 130)\n",
      "img:  (68000, 66, 130) -2.0829253 2.1060908 float32\n"
     ]
    }
   ],
   "source": [
    "# load images\n",
    "img = data.load_images(data_path, mouse_id, file=data.img_file_name[mouse_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loading activities from ./data/FX20_nat60k_2023_09_29.npz\n"
     ]
    }
   ],
   "source": [
    "# load neurons\n",
    "fname = '%s_nat60k_%s.npz'%(data.db[mouse_id]['mname'], data.db[mouse_id]['datexp'])\n",
    "spks, istim_train, istim_test, xpos, ypos, spks_rep_all = data.load_neurons(file_path = os.path.join(data_path, fname), mouse_id = mouse_id)\n",
    "n_stim, n_neurons = spks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "splitting training and validation set...\n",
      "itrain:  (43081,)\n",
      "ival:  (4787,)\n"
     ]
    }
   ],
   "source": [
    "# split train and validation set\n",
    "itrain, ival = data.split_train_val(istim_train, train_frac=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "normalizing neural data...\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "# normalize data\n",
    "spks, spks_rep_all = data.normalize_spks(spks, spks_rep_all, itrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spks_train:  torch.Size([43081, 2746]) tensor(-1.4092e-15, device='cuda:0') tensor(48.7427, device='cuda:0')\n",
      "spks_val:  torch.Size([4787, 2746]) tensor(-6.8745e-16, device='cuda:0') tensor(44.7361, device='cuda:0')\n",
      "img_train:  torch.Size([43081, 1, 66, 130]) tensor(-2.0829, device='cuda:0') tensor(2.1061, device='cuda:0')\n",
      "img_val:  torch.Size([4787, 1, 66, 130]) tensor(-2.0829, device='cuda:0') tensor(2.1061, device='cuda:0')\n",
      "img_test:  torch.Size([500, 1, 66, 130]) tensor(-2.0829, device='cuda:0') tensor(2.1061, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "ineur = np.arange(0, n_neurons) #np.arange(0, n_neurons, 5)\n",
    "spks_train = torch.from_numpy(spks[itrain][:,ineur]).to(device)\n",
    "spks_val = torch.from_numpy(spks[ival][:,ineur]).to(device)\n",
    "\n",
    "print('spks_train: ', spks_train.shape, spks_train.min(), spks_train.max())\n",
    "print('spks_val: ', spks_val.shape, spks_val.min(), spks_val.max())\n",
    "\n",
    "img_train = torch.from_numpy(img[istim_train][itrain]).to(device).unsqueeze(1) # change :130 to 25:100 \n",
    "img_val = torch.from_numpy(img[istim_train][ival]).to(device).unsqueeze(1)\n",
    "img_test = torch.from_numpy(img[istim_test]).to(device).unsqueeze(1)\n",
    "\n",
    "print('img_train: ', img_train.shape, img_train.min(), img_train.max())\n",
    "print('img_val: ', img_val.shape, img_val.min(), img_val.max())\n",
    "print('img_test: ', img_test.shape, img_test.min(), img_test.max())\n",
    "\n",
    "input_Ly, input_Lx = img_train.shape[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core shape:  torch.Size([1, 320, 33, 65])\n",
      "input shape of readout:  (320, 33, 65)\n",
      "model name:  FX20_092923_2layer_16_320_clamp_norm_depthsep_pool_xrange_176.pt\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "from minimodel import model_builder\n",
    "nlayers = 2\n",
    "nconv1 = 16\n",
    "nconv2 = 320\n",
    "model, in_channels = model_builder.build_model(NN=len(ineur), n_layers=nlayers, n_conv=nconv1, n_conv_mid=nconv2)\n",
    "model_name = model_builder.create_model_name(data.mouse_names[mouse_id], data.exp_date[mouse_id], n_layers=nlayers, in_channels=in_channels)\n",
    "\n",
    "model_path = os.path.join(weight_path, model_name)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Learning rate = 0.001\n",
      "epoch 0, train_loss = 0.8419, val_loss = 0.8176, varexp_val = 0.0475, time 53.73s\n",
      "epoch 1, train_loss = 0.8119, val_loss = 0.8054, varexp_val = 0.0669, time 101.58s\n",
      "epoch 2, train_loss = 0.8030, val_loss = 0.7968, varexp_val = 0.0794, time 149.44s\n",
      "epoch 3, train_loss = 0.7978, val_loss = 0.7931, varexp_val = 0.0858, time 197.29s\n",
      "epoch 4, train_loss = 0.7949, val_loss = 0.7907, varexp_val = 0.0895, time 245.13s\n",
      "epoch 5, train_loss = 0.7926, val_loss = 0.7903, varexp_val = 0.0906, time 292.92s\n",
      "epoch 6, train_loss = 0.7908, val_loss = 0.7879, varexp_val = 0.0941, time 340.57s\n",
      "epoch 7, train_loss = 0.7896, val_loss = 0.7872, varexp_val = 0.0955, time 388.29s\n",
      "epoch 8, train_loss = 0.7886, val_loss = 0.7865, varexp_val = 0.0962, time 436.01s\n",
      "epoch 9, train_loss = 0.7876, val_loss = 0.7855, varexp_val = 0.0984, time 483.72s\n",
      "epoch 10, train_loss = 0.7869, val_loss = 0.7847, varexp_val = 0.0993, time 531.43s\n",
      "epoch 11, train_loss = 0.7862, val_loss = 0.7848, varexp_val = 0.0995, time 579.13s\n",
      "epoch 12, train_loss = 0.7857, val_loss = 0.7844, varexp_val = 0.0999, time 626.84s\n",
      "epoch 13, train_loss = 0.7852, val_loss = 0.7840, varexp_val = 0.1008, time 674.58s\n",
      "epoch 14, train_loss = 0.7848, val_loss = 0.7854, varexp_val = 0.0996, time 722.30s\n",
      "epoch 15, train_loss = 0.7843, val_loss = 0.7833, varexp_val = 0.1018, time 770.03s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(device)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_path):\n\u001b[0;32m----> 6\u001b[0m     best_state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspks_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspks_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(best_state_dict, model_path)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved model\u001b[39m\u001b[38;5;124m'\u001b[39m, model_path)\n",
      "File \u001b[0;32m/mnt/vast-nhr/projects/bthesis_cidas_richter/benjamin/minimodel/minimodel/model_trainer.py:138\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, spks_train, spks_val, img_train, img_val, l2_readout, hs_readout, clamp, device, n_epochs_period, batch_size, patience)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m    137\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 138\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mimg_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspks_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetach_core\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetach_core\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhs_reg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhs_readout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    143\u001b[0m     val_loss, varexp, _ \u001b[38;5;241m=\u001b[39m val_epoch(model, img_val, spks_val, \n\u001b[1;32m    144\u001b[0m                                                                 batch_size\u001b[38;5;241m=\u001b[39mbatch_size, \n\u001b[1;32m    145\u001b[0m                                                                 device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m/mnt/vast-nhr/projects/bthesis_cidas_richter/benjamin/minimodel/minimodel/model_trainer.py:102\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, img_train, spks_train, epoch, batch_size, l1_readout, device, detach_core, clamp, parallel, hs_reg)\u001b[0m\n\u001b[1;32m    100\u001b[0m             model\u001b[38;5;241m.\u001b[39mreadout\u001b[38;5;241m.\u001b[39mWx\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mclamp_(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    101\u001b[0m             model\u001b[38;5;241m.\u001b[39mreadout\u001b[38;5;241m.\u001b[39mWy\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mclamp_(\u001b[38;5;241m0\u001b[39m) \n\u001b[0;32m--> 102\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m loss\n\u001b[1;32m    104\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m n_train\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model\n",
    "from minimodel import model_trainer\n",
    "print(device)\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    best_state_dict = model_trainer.train(model, spks_train, spks_val, img_train, img_val, device=device)\n",
    "    torch.save(best_state_dict, model_path)\n",
    "    print('saved model', model_path)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "print('loaded model', model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_pred:  (500, 2746) 0.0017536283 8.742443\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "test_pred = model_trainer.test_epoch(model, img_test)\n",
    "print('test_pred: ', test_pred.shape, test_pred.min(), test_pred.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering neurons with FEV > 0.15\n",
      "valid neurons: 1239 / 2746\n",
      "FEVE (test): 0.7267250418663025\n"
     ]
    }
   ],
   "source": [
    "from minimodel import metrics\n",
    "test_fev, test_feve = metrics.feve(spks_rep_all, test_pred)\n",
    "\n",
    "threshold = 0.15\n",
    "print(f'filtering neurons with FEV > {threshold}')\n",
    "valid_idxes = np.where(test_fev > threshold)[0]\n",
    "print(f'valid neurons: {len(valid_idxes)} / {len(test_fev)}')\n",
    "print(f'FEVE (test): {np.mean(test_feve[test_fev > threshold])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minimodel-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
